{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hashtag_london_batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOy+up9L0ln8fPsRQ7tVte+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StanHillServian/hashtag-london-stream/blob/main/hashtag_london_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlqqot3WTPN"
      },
      "source": [
        "# BATCH feed to get #london data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N4ma_yb9ADw"
      },
      "source": [
        "To test the functionality of Tweepy, I have created this quick batch script, that gets the latest 100 #london tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1xM6cVYIh37"
      },
      "source": [
        "# Imports and Auth\n",
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "#### Auth steps\n",
        "consumer_key = 'lbRF9YBBJvAaDPrT1PbyjIVKD'\n",
        "consumer_secret = 'OL0Gg0XrDtMdHcwvyocPw7ZwvZJvlhZcMWAVi28vWiUOjejWP3'\n",
        "access_token = '1319427930439749633-MLh2G2POhQbcCIEHXMHmRcVQxrMizR'\n",
        "access_token_secret = 'bPb6zZAN7zICHbAhwbq23Ju24igdsf0ALOBTstE1Qfr8C'"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CYOjKBvTZVA"
      },
      "source": [
        "def main():\n",
        "  auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "  auth.set_access_token(access_token, access_token_secret)\n",
        "  api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "\n",
        "  ## Get latest 50 #london tweets.\n",
        "\n",
        "  hashtag = \"#london\"\n",
        "  tweets = []\n",
        "  for tweet in tweepy.Cursor(api.search,q=hashtag,\n",
        "                            lang=\"en\",\n",
        "                            result_type=\"recent\").items(100):\n",
        "\n",
        "  #If there is a media attachement to the Tweet, display the media url.\n",
        "    if 'media' in tweet.entities:\n",
        "      for image in tweet.entities['media']:\n",
        "        image_content = image['media_url']\n",
        "    else:\n",
        "      image_content = None\n",
        "\n",
        " # Adjusting creating time for London timezone. I know there's definitely a better way to do this, don't have time to work out how.\n",
        "    adjusted_creation_time = tweet.created_at+timedelta(hours=1)\n",
        "\n",
        "    tweets.append([adjusted_creation_time, tweet.text.encode('utf-8'), image_content, tweet.user.screen_name])\n",
        "    \n",
        "\n",
        "  tweets = pd.DataFrame(tweets,columns=['Created At', 'Tweet Text', 'Media URL', 'User (Handle)'])\n",
        "\n",
        "  ## Export to CSV\n",
        "  tweets.to_csv(path_or_buf='latest_100_london.csv')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 100,
      "outputs": []
    }
  ]
}