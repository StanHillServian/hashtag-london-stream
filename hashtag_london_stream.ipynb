{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hashtag_london_stream.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8RXAC5raUm7B2LvbL7BuS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StanHillServian/hashtag-london-stream/blob/main/hashtag_london_stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x3p3ujUcN-E"
      },
      "source": [
        "import sys\n",
        "\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import API\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "import json\n",
        "\n",
        "# Replace the \"None\"s by your own credentials\n",
        "ACCESS_TOKEN = '1319427930439749633-MLh2G2POhQbcCIEHXMHmRcVQxrMizR'\n",
        "ACCESS_TOKEN_SECRET = 'bPb6zZAN7zICHbAhwbq23Ju24igdsf0ALOBTstE1Qfr8C'\n",
        "CONSUMER_KEY = 'lbRF9YBBJvAaDPrT1PbyjIVKD'\n",
        "CONSUMER_SECRET = 'OL0Gg0XrDtMdHcwvyocPw7ZwvZJvlhZcMWAVi28vWiUOjejWP3'\n",
        "\n",
        "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = API(auth, wait_on_rate_limit=True,\n",
        "          wait_on_rate_limit_notify=True)\n",
        "\n",
        "class Listener(StreamListener):\n",
        "    def __init__(self, output_file=sys.stdout):\n",
        "        super(Listener,self).__init__()\n",
        "        self.output_file = output_file\n",
        "    def on_status(self, status):\n",
        "      data = {}\n",
        "      data['created_at'] = str(status.created_at)\n",
        "      data['tweet'] = status.text\n",
        "      data['handle'] = status.user.screen_name\n",
        "      json.dump(data, self.output_file)\n",
        "        #print([status.created_at, status.text, status.user.screen_name, file=self.output_file)\n",
        "    def on_error(self, status_code):\n",
        "        print(status_code)\n",
        "        return False\n",
        "\n",
        "\n",
        "output = open('stream_output.json', 'w')\n",
        "listener = Listener(output_file=output)\n",
        "\n",
        "stream = Stream(auth=api.auth, listener=listener)\n",
        "try:\n",
        "    print('Start streaming.')\n",
        "    stream.filter(track=['#london'])\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopped.\")\n",
        "finally:\n",
        "    print('Done.')\n",
        "    stream.disconnect()\n",
        "    output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqZdi3XHG1Jd"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# Copyright 2015 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"This script uses the Twitter Streaming API, via the tweepy library,\n",
        "to pull in tweets and publish them to a PubSub topic.\n",
        "\"\"\"\n",
        "\n",
        "import base64\n",
        "import datetime\n",
        "import os\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "import json \n",
        "\n",
        "##import utils\n",
        "\n",
        "# Get your twitter credentials from the environment variables.\n",
        "# These are set in the 'twitter-stream.json' manifest file.\n",
        "\n",
        "consumer_key = 'lbRF9YBBJvAaDPrT1PbyjIVKD'\n",
        "consumer_secret = 'OL0Gg0XrDtMdHcwvyocPw7ZwvZJvlhZcMWAVi28vWiUOjejWP3'\n",
        "access_token = '1319427930439749633-MLh2G2POhQbcCIEHXMHmRcVQxrMizR'\n",
        "access_token_secret = 'bPb6zZAN7zICHbAhwbq23Ju24igdsf0ALOBTstE1Qfr8C'\n",
        "\n",
        "#PUBSUB_TOPIC = os.environ['PUBSUB_TOPIC']\n",
        "NUM_RETRIES = 3\n",
        "\n",
        "class newdict(dict):\n",
        "        def __str__(self):\n",
        "            return json.dumps(self)\n",
        "\n",
        "def publish(data_lines):\n",
        "\n",
        "    messages = []\n",
        "    \"\"\"Publish to the given pubsub topic.\"\"\"\n",
        "    #for line in data_lines:\n",
        "     #   print(\"PRINTING LINE\")\n",
        "     #   print(type(line))\n",
        "     #   print(line)\n",
        "    #    res = json.loads(line)\n",
        "    #    message = str(cleanup(res))\n",
        "        #print(\"PRINTING MESSAGE CLEANED UP\")\n",
        "        #print(type(message))\n",
        "        #print(message)\n",
        "    \n",
        "    for line in data_lines:\n",
        "      print(line)\n",
        "      data = json.loads(line)\n",
        "      try:\n",
        "        user = data[\"user\"]\n",
        "        clean_data=json.dumps({\n",
        "              \"text\": data[\"text\"],\n",
        "              \"user_handle\": user[\"screen_name\"],\n",
        "              \"id\": data[\"id\"],\n",
        "              \"posted_at\": data[\"created_at\"]\n",
        "           }).encode('utf-8')\n",
        "        pub = base64.urlsafe_b64encode(clean_data)\n",
        "        messages.append({'data': pub})\n",
        "     \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "\n",
        "        \n",
        "    body = {'messages': messages}\n",
        "    print(body)\n",
        "\n",
        "    #body = {'messages': messages}\n",
        "    #print(\"publish message: %s\" % line)\n",
        "    #resp = client.projects().topics().publish(\n",
        "            #topic=pubsub_topic, body=body).execute(num_retries=NUM_RETRIES)\n",
        "    #return resp\n",
        "\n",
        "\n",
        "def cleanup(data):\n",
        "  if isinstance(data, dict):\n",
        "    newlist = []\n",
        "\n",
        "    for k, v in data.items():\n",
        "      if (k == 'retweeted_status') and isinstance(v, dict):\n",
        "        for a, b in v.items():\n",
        "          if (a == 'extended_tweet') and isinstance(b, dict):\n",
        "            for c, d in b.items():\n",
        "              if (c == 'full_text') and isinstance(d, str):\n",
        "                newlist.append([c, d])\n",
        "      if (k == 'text') and isinstance(v, str):\n",
        "        newlist.append([k, v])\n",
        "      elif k == 'created_at' and v:\n",
        "        newlist.append([k, v])\n",
        "      elif k == 'user' and isinstance(v, dict):\n",
        "        for a, b in v.items():\n",
        "         if (a == 'screen_name') and isinstance(b, str):\n",
        "          newlist.append([a, b])\n",
        "\n",
        "    mydict = newdict(newlist)\n",
        "    return mydict\n",
        "  else:\n",
        "    return data\n",
        "    \n",
        " \n",
        "          \n",
        "\n",
        "\n",
        "class StdOutListener(StreamListener):\n",
        "    \"\"\"A listener handles tweets that are received from the stream.\n",
        "    This listener dumps the tweets into a PubSub topic\n",
        "    \"\"\"\n",
        "\n",
        "    count = 0\n",
        "    twstring = ''\n",
        "    tweets = []\n",
        "    batch_size = 3\n",
        "    total_tweets = 10000000\n",
        "    #client = utils.create_pubsub_client(utils.get_credentials())\n",
        "\n",
        "    def write_to_pubsub(self, tw):\n",
        "        publish(tw)\n",
        "\n",
        "    def on_data(self, data):\n",
        "        \"\"\"What to do when tweet data is received.\"\"\"\n",
        "        self.tweets.append(data)\n",
        "        if len(self.tweets) >= self.batch_size:\n",
        "            self.write_to_pubsub(self.tweets)\n",
        "            self.tweets = []\n",
        "        self.count += 1\n",
        "        # if we've grabbed more than total_tweets tweets, exit the script.\n",
        "        # If this script is being run in the context of a kubernetes\n",
        "        # replicationController, the pod will be restarted fresh when\n",
        "        # that happens.\n",
        "        if self.count > self.total_tweets:\n",
        "            return False\n",
        "        if (self.count % 1000) == 0:\n",
        "            print(\"count is: %s at %s\" % (self.count, datetime.datetime.now()))\n",
        "        return True\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('....')\n",
        "    listener = StdOutListener()\n",
        "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "    auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "    #print('stream mode is: %s' % os.environ['TWSTREAMMODE'])\n",
        "\n",
        "    stream = Stream(auth, listener, tweet_mode='extended')\n",
        "    # set up the streaming depending upon whether our mode is 'filter', which\n",
        "    # will stream the #london hashtag. If it is not, it will sample random \n",
        "    # This environment var is set in the 'twitter-stream.yaml' file.\n",
        "    stream.filter(track=['#london'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EfjMzbdRrcg",
        "outputId": "a3abbf3c-84ab-4342-b2ee-2f4face76602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import tweepy\n",
        "from google.cloud import pubsub_v1\n",
        "\n",
        "# Authenticate\n",
        "auth = tweepy.OAuthHandler('lbRF9YBBJvAaDPrT1PbyjIVKD', 'OL0Gg0XrDtMdHcwvyocPw7ZwvZJvlhZcMWAVi28vWiUOjejWP3')\n",
        "auth.set_access_token('1319427930439749633-MLh2G2POhQbcCIEHXMHmRcVQxrMizR', 'bPb6zZAN7zICHbAhwbq23Ju24igdsf0ALOBTstE1Qfr8C')\n",
        "\n",
        "# Configure to wait on rate limit if necessary\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=False)\n",
        "\n",
        "# Hashtag\n",
        "hashtag = \"#london\"\n",
        "\n",
        "# Function to write data to\n",
        "def write_to_pubsub(data):\n",
        "    try:\n",
        "      # publish to the topic, don't forget to encode everything at utf8!\n",
        "      publisher.publish(topic_path, data=json.dumps({\n",
        "          \"text\": data[\"text\"],\n",
        "          \"user_id\": data[\"user_id\"],\n",
        "          \"id\": data[\"id\"],\n",
        "          \"posted_at\": datetime.datetime.fromtimestamp(data[\"created_at\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
        "      }).encode(\"utf-8\"), tweet_id=str(data[\"id\"]).encode(\"utf-8\"))\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "def cleanup(data):\n",
        "  if isinstance(data, dict):\n",
        "    newdict = {}\n",
        "\n",
        "    for k, v in data.items():\n",
        "      if (k == 'retweeted_status') and isinstance(v, dict):\n",
        "        for a, b in v.items():\n",
        "          if (a == 'extended_tweet') and isinstance(b, dict):\n",
        "            for c, d in b.items():\n",
        "              if (c == 'full_text') and isinstance(d, str):\n",
        "                newdict[\"full_tweet\"] = d\n",
        "      if (k == 'text') and isinstance(v, str):\n",
        "        newdict[\"tweet\"] = v\n",
        "      elif k == 'created_at' and v:\n",
        "        newdict[k] = v\n",
        "      elif k == 'user' and isinstance(v, dict):\n",
        "        for a, b in v.items():\n",
        "         if (a == 'screen_name') and isinstance(b, str):\n",
        "          newdict[a] = b\n",
        "    print(newdict)\n",
        "    return newdict\n",
        "  else:\n",
        "    return data\n",
        "\n",
        "# Listener class\n",
        "class TweetListener(StreamListener):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def on_status(self, data):\n",
        "        # When receiveing a tweet: send it to pubsub\n",
        "        print(data)\n",
        "        write_to_pubsub(cleanup(data._json))\n",
        "        return True\n",
        "\n",
        "    def on_error(self, status):\n",
        "        if status == 420:\n",
        "            print(\"rate limit active\")\n",
        "            return False\n",
        "          \n",
        "# Make an instance of the class\n",
        "l = TweetListener()\n",
        "\n",
        "# Start streaming\n",
        "stream = tweepy.Stream(auth, l, tweet_mode='extended')\n",
        "stream.filter(track=hashtag)\n",
        "\n",
        "# Configure the connection\n",
        "publisher = pubsub_v1.PublisherClient()\n",
        "topic_path = publisher.topic_path('servian-task', 'hashtag-london-topic-2')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ab3e5ca6d630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpubsub_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Authenticate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbRF9YBBJvAaDPrT1PbyjIVKD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OL0Gg0XrDtMdHcwvyocPw7ZwvZJvlhZcMWAVi28vWiUOjejWP3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'pubsub_v1'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}